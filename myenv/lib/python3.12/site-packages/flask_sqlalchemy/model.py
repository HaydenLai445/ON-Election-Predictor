from __future__ import annotations

import re
import typing as t

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import sqlalchemy as sa
import sqlalchemy.orm as sa_orm

from .query import Query

if t.TYPE_CHECKING:
    from .extension import SQLAlchemy


class _QueryProperty:
    """A class property that creates a query object for a model.

    :meta private:
    """

    def __get__(self, obj: Model | None, cls: type[Model]) -> Query:
        return cls.query_class(
            cls, session=cls.__fsa__.session()  # type: ignore[arg-type]
        )


class Model:
    """The base class of the :attr:`.SQLAlchemy.Model` declarative model class.

    To define models, subclass :attr:`db.Model <.SQLAlchemy.Model>`, not this. To
    customize ``db.Model``, subclass this and pass it as ``model_class`` to
    :class:`.SQLAlchemy`. To customize ``db.Model`` at the metaclass level, pass an
    already created declarative model class as ``model_class``.
    """

    __fsa__: t.ClassVar[SQLAlchemy]
    """Internal reference to the extension object.

    :meta private:
    """

    query_class: t.ClassVar[type[Query]] = Query
    """Query class used by :attr:`query`. Defaults to :attr:`.SQLAlchemy.Query`, which
    defaults to :class:`.Query`.
    """

    query: t.ClassVar[Query] = _QueryProperty()  # type: ignore[assignment]
    """A SQLAlchemy query for a model. Equivalent to ``db.session.query(Model)``. Can be
    customized per-model by overriding :attr:`query_class`.

    .. warning::
        The query interface is considered legacy in SQLAlchemy. Prefer using
        ``session.execute(select())`` instead.
    """

    def __repr__(self) -> str:
        state = sa.inspect(self)
        assert state is not None

        if state.transient:
            pk = f"(transient {id(self)})"
        elif state.pending:
            pk = f"(pending {id(self)})"
        else:
            pk = ", ".join(map(str, state.identity))

        return f"<{type(self).__name__} {pk}>"


class ElectionModel(Model):
    """A model for election data."""

    __tablename__ = "election_data"

    id = sa.Column(sa.Integer, primary_key=True)
    riding = sa.Column(sa.String)
    party = sa.Column(sa.String)
    vote_percentage = sa.Column(sa.Float)
    star_candidate = sa.Column(sa.Boolean)
    election_outcome = sa.Column(sa.String)  # Target variable (e.g., "win", "lose")


def load_and_preprocess_data():
    """Load and preprocess historical election and polling data."""
    # Load historical election data
    historical_data = pd.read_csv("data/historical_election_data.csv")

    # Load polling data
    polling_data = pd.read_csv("data/polling_data.csv")

    # Merge data on riding and date
    merged_data = pd.merge(historical_data, polling_data, on=["riding", "date"], how="inner")

    # Feature engineering
    merged_data["star_candidate"] = merged_data["star_candidate"].apply(lambda x: 1 if x == "yes" else 0)

    # Normalize features
    scaler = StandardScaler()
    features = ["vote_percentage", "polling_percentage", "star_candidate"]
    merged_data[features] = scaler.fit_transform(merged_data[features])

    return merged_data


def train_model(data):
    """Train a machine learning model."""
    # Define features and target
    X = data[["vote_percentage", "polling_percentage", "star_candidate"]]
    y = data["election_outcome"]

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)

    # Evaluate the model
    accuracy = model.score(X_test, y_test)
    print(f"Model Accuracy: {accuracy:.2f}")

    return model


def make_predictions(model, new_data):
    """Make predictions using the trained model."""
    # Preprocess new data
    scaler = StandardScaler()
    features = ["vote_percentage", "polling_percentage", "star_candidate"]
    new_data[features] = scaler.fit_transform(new_data[features])

    # Make predictions
    predictions = model.predict(new_data[features])
    new_data["predicted_outcome"] = predictions

    return new_data


# Example usage
if __name__ == "__main__":
    # Load and preprocess data
    data = load_and_preprocess_data()

    # Train the model
    model = train_model(data)

    # Load new polling data
    new_polling_data = pd.read_csv("data/new_polling_data.csv")

    # Make predictions
    predictions = make_predictions(model, new_polling_data)
    print(predictions)